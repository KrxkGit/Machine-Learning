{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7959a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ResNetConfig,ResNetModel,BertTokenizer,Trainer,TrainingArguments\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import pickle\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f52a37f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer = BertTokenizer('./vocab.txt')\n",
    "vocab_size = tokenizer.vocab_size\n",
    "# encoder\n",
    "config_encoder = ResNetConfig()\n",
    "model_encoder = ResNetModel(config=config_encoder)\n",
    "# decoder\n",
    "model_decoder = nn.Transformer(batch_first=True)\n",
    "\n",
    "def ClearSpecialChar(decodings):\n",
    "    return ''.replace('[CLS]','').replace('[UNK]','').replace('[PAD]','').replace('[SEP]',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26b3d525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[101, 100, 133, 166, 100, 515, 489, 117, 490, 517, 122, 125, 102],\n",
      "        [101, 100, 133, 166, 100, 515, 489, 117, 490, 517, 122, 125, 102]])\n",
      "torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "# 测试 tokenizer\n",
    "test_caption = r'Krxk:\\frac{a+b}/2' # 采用原生字符串\n",
    "t = tokenizer.encode(test_caption,return_tensors='pt')\n",
    "t = t.repeat((2, 1))\n",
    "print(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3255465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 caption\n",
    "# 纯数学公式\n",
    "save_cwd = os.getcwd()\n",
    "\n",
    "root_dir = 'F:/DP-Dataset/dataset-formula/'\n",
    "os.chdir(root_dir)\n",
    "train_dir = root_dir + 'train'\n",
    "val_dir = root_dir + 'dev'\n",
    "\n",
    "out_path_mid = root_dir.split('/')[-2].replace('dataset-', '') + '_'\n",
    "\n",
    "with open(out_path_mid + 'train_out', 'rb') as f:\n",
    "    train_labels = pickle.load(f)\n",
    "\n",
    "with open(out_path_mid + 'dev_out', 'rb') as f:\n",
    "    val_labels = pickle.load(f)\n",
    "\n",
    "with open(out_path_mid + 'test_out', 'rb') as f:\n",
    "    test_labels = pickle.load(f)\n",
    "\n",
    "os.chdir(save_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97f13734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于整合 Image 与 Caption，构造 Image-Caption 数据集，同时预先对label进行tokenize(tokenize后为二维，压缩0维)\n",
    "max_length = 80\n",
    "class Compose_Dataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, image_dataset, caption_list, tokenizer):\n",
    "        super().__init__()\n",
    "        self.image_dataset = image_dataset\n",
    "        self.caption_list = caption_list\n",
    "        self.imgs = image_dataset.imgs\n",
    "        self.tokenizer = tokenizer\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.caption_list['id'].index(self.imgs[idx][0].split('\\\\')[-1].replace('png', 'txt'))\n",
    "        return {'X':self.image_dataset[idx][0], 'labels':self.tokenizer.encode(\n",
    "            self.caption_list['label'][index], padding='max_length', truncation=True, max_length=max_length, return_tensors='pt').squeeze()}\n",
    "    def __len__(self):\n",
    "        return len(self.image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c1cc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12469\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集\n",
    "train_dir = 'F:/DP-Dataset/s'\n",
    "val_dir = 'F:/DP-Dataset/test/'\n",
    "data_args = transforms.Compose([\n",
    "    transforms.Pad([200, 200]), # 填充\n",
    "    transforms.Resize((200,200), interpolation=Image.Resampling.BICUBIC), # 调整为正方形并统一大小\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_set = datasets.ImageFolder(train_dir, transform=data_args)\n",
    "val_set = datasets.ImageFolder(val_dir, transform=data_args)\n",
    "\n",
    "compose_train_set = Compose_Dataset(train_set, train_labels, tokenizer)\n",
    "compose_val_set = Compose_Dataset(val_set, val_labels, tokenizer)\n",
    "\n",
    "batch_size = 32\n",
    "data_iter = torch.utils.data.DataLoader(compose_train_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "252c295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 200, 200])\n",
      "tensor([101, 166, 100, 166, 515, 489, 487, 515, 502, 517, 166, 100, 166, 517,\n",
      "        102,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 测试数据集\n",
    "for dic in data_iter:\n",
    "    X = dic['X']\n",
    "    label = dic['labels']\n",
    "    # X 是一个 batch\n",
    "    print(X.shape)\n",
    "    test_id = 0\n",
    "    print(label[test_id])\n",
    "    plt.imshow(X[test_id][0]) # 查看 R 通道\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e89f4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "def Loss(src, tgt):\n",
    "    src = torch.permute(src, dims=(0, 2, 1)) # 根据官方文档，分类必须在\n",
    "#     print(src.shape, tgt.shape)\n",
    "    return F.cross_entropy(src, tgt)\n",
    "\n",
    "class Krxk_model(nn.Module):\n",
    "    def __init__(self, tokenizer, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.encoder = encoder\n",
    "        self.embed_size = self.tokenizer.vocab_size\n",
    "        self.transformer_encoder_in_nums = 512\n",
    "        self.fc = nn.Sequential(nn.Flatten(), nn.Linear(2048 * 7 * 7, self.transformer_encoder_in_nums)) # 将 resnet 转化为 全连接\n",
    "        self.embed = nn.Embedding(self.embed_size, self.transformer_encoder_in_nums) # 嵌入为 transformer的in_features维度\n",
    "        self.decoder = decoder\n",
    "        self.fc_vocab = nn.Linear(self.transformer_encoder_in_nums, self.embed_size) # transformer 输出映射回词表\n",
    "        \n",
    "        # 用作临时 caption 测试案例\n",
    "#         test_caption = 'Krxk is a great developer.' \n",
    "#         print(test_caption)\n",
    "#         self.test_caption_tokenized = self.tokenizer.encode(test_caption, return_tensors='pt').repeat(6, 1) # 临时案例中有6张图片\n",
    "#         print(self.test_caption_tokenized.shape)\n",
    "#         print(self.embed(self.test_caption_tokenized).shape)\n",
    "        \n",
    "    def forward(self, X, labels):\n",
    "        encode = self.encoder(X).last_hidden_state\n",
    "        features = self.fc(encode) # 将图片特征映射为词表特征\n",
    "        \n",
    "        # 此处将 embeddings 与 resnet 提取的特征进行concat 输入 transformer\n",
    "#         embeddings = torch.concat((embeddings, embeddings), dim=1)\n",
    "        embeddings = self.embed(labels)\n",
    "        f = features.unsqueeze(1)\n",
    "#         print(embeddings.shape, f.shape)\n",
    "        embeddings_attach = torch.concat((embeddings, features.unsqueeze(1)), dim=1)\n",
    "\n",
    "        # decode 需要输入 src 与 tgt，分别用作 Transformer 编码器与解码器（输入正确的caption）的输入\n",
    "        decode = self.decoder(embeddings_attach, embeddings)\n",
    "        decode_ids = self.fc_vocab(decode)\n",
    "        \n",
    "        \n",
    "        return Loss(decode_ids, labels),decode_ids # 损失放在第一返回位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1feb2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 model\n",
    "model = Krxk_model(tokenizer ,model_encoder, model_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f4e8eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 model 保存的参数\n",
    "res_path = './Params/'\n",
    "Model_path = res_path + 'Model.bin'\n",
    "\n",
    "if os.path.exists(Model_path):\n",
    "    model.load_state_dict(torch.load(Model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab5c8cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 200, 200])\n",
      "torch.Size([4, 80])\n",
      "tensor(1.6307, grad_fn=<NllLoss2DBackward0>) torch.Size([4, 80, 519])\n"
     ]
    }
   ],
   "source": [
    "# 模型测试\n",
    "model.eval() # 评估模式运行减少计算量\n",
    "for dic in data_iter:\n",
    "    X = dic['X']\n",
    "    label = dic['labels']\n",
    "    print(X.shape)\n",
    "    print(label.shape)\n",
    "    l, generated_ids = model.forward(X, label)\n",
    "    print(l, generated_ids.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cb01c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 metric\n",
    "evaluate_path = 'F:/DEVELOP/Machine-Learning/SRP/evaluate/metrics/'\n",
    "bleu_path = evaluate_path + 'bleu/bleu.py'\n",
    "wer_path = evaluate_path + 'wer/wer.py'\n",
    "accuracy_path = evaluate_path + 'accuracy/accuracy.py'\n",
    "\n",
    "bleu = evaluate.load(bleu_path)\n",
    "wer = evaluate.load(wer_path)\n",
    "accuracy = evaluate.load(accuracy_path)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred): # 修改此处\n",
    "    predictions, label_ids = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    items_num = len(predictions)\n",
    "    total_accuracy = 0.0\n",
    "    total_bleu = 0.0\n",
    "    total_wer = 0.0\n",
    "    total_summary = 0.0\n",
    "    \n",
    "    \n",
    "    for i in range(items_num):\n",
    "        params_accuracy = {'predictions':predictions[i], 'references':label_ids[i]}\n",
    "        total_accuracy += accuracy.compute(**params_accuracy)['accuracy']\n",
    "        \n",
    "        de_prediction = tokenizer.decode(predictions[i])\n",
    "        de_label = tokenizer.decode(label_ids[i])\n",
    "        # 截断为共同长度\n",
    "        spec_len = min(len(de_prediction), len(de_label))\n",
    "        de_prediction = de_prediction[:spec_len]\n",
    "        de_label = de_label[:spec_len]\n",
    "#         print('de_predition',len(de_prediction))\n",
    "#         print('de_label',len(de_label))\n",
    "        \n",
    "        params_bleu = {'predictions':de_prediction, 'references':de_label}\n",
    "        params_wer = {'predictions':[de_prediction], 'references':[de_label]}\n",
    "        \n",
    "        total_bleu += bleu.compute(**params_bleu)['bleu']\n",
    "        total_wer += wer.compute(**params_wer)\n",
    "    \n",
    "    total_summary = (total_accuracy + total_bleu + total_wer) / 3\n",
    "    return {'bleu': total_bleu / items_num, 'wer' : total_wer / items_num ,\n",
    "            'accuracy' : total_accuracy / items_num , 'summary' : total_summary / items_num}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca8bc80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练参数\n",
    "training_args = TrainingArguments('./output',evaluation_strategy='epoch',save_strategy='epoch', learning_rate=5e-3, \n",
    "                                    load_best_model_at_end=True, num_train_epochs=2, use_cpu=True) # 暂时采用CPU\n",
    "trainer = Trainer(model, args=training_args, train_dataset=compose_train_set, eval_dataset=compose_val_set, \n",
    "                  compute_metrics=compute_metrics) # 修改数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45417eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:10, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.372145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163331</td>\n",
       "      <td>0.840625</td>\n",
       "      <td>0.334652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.218642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163331</td>\n",
       "      <td>0.840625</td>\n",
       "      <td>0.334652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2, training_loss=1.2826757431030273, metrics={'train_runtime': 14.6188, 'train_samples_per_second': 0.547, 'train_steps_per_second': 0.137, 'total_flos': 0.0, 'train_loss': 1.2826757431030273, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 训练\n",
    "trainer.train(resume_from_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9350413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Gen:  [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "0 Rand:  \\arctan \\bmod \\sb [unused58] \\bigoplus \\hspace 4 [unused83] [unused34] \\left\\lbrack [unused34] [unused87] v F [unused64] \\varepsilon \\sharp \\stackrel \\mathrm \\left[ \\\\ \\subseteq [unused46] \\jmath \\cong \\circle \\tilde \\fbox \\perp \\star \\downarrow ( \\i \\kappa ^ \\Upsilon \\! \\flat \\right> Q \\beta \\longleftrightarrow \\scriptstyle \\Rightarrow \\mid [PAD] \\in \" \\Sigma \\begin{array} [unused88] \\tau j [unused34] a [unused7] \\_ \\longmapsto \\varsigma \\mathrm \\enskip \\backslash \\sqrt 0 [unused100] \\big a \\oint \\ell S \\subseteq \\boldmath 1 \\vec \\boldsymbol \\: \\raise [unused25] \\kappa [unused85]\n"
     ]
    }
   ],
   "source": [
    "# 预测代码测试\n",
    "eval_pred =  trainer.predict(test_dataset=compose_train_set)\n",
    "predictions = eval_pred.predictions\n",
    "for i, item in enumerate(predictions):\n",
    "    item_like = np.random.randn(*item.shape) # 随机对照\n",
    "    decodings = tokenizer.decode(np.argmax(item, axis=-1))\n",
    "    decodings_like = tokenizer.decode(np.argmax(item_like, axis=-1))\n",
    "    print(f'{i} Gen: ', decodings)\n",
    "    print(f'{i} Rand: ', decodings_like)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a85c0086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "tokenizer.save_pretrained(res_path)\n",
    "torch.save(model.state_dict(), Model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "632ccd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('F:/DP-Dataset/test_end/1\\\\16.png', 0)\n"
     ]
    }
   ],
   "source": [
    "# 进行最终预测\n",
    "\n",
    "test_pic = 'F:/DP-Dataset/test_end/' # test 图片路径\n",
    "id_file_path = 'F:/DP-Dataset/test_end_id.txt'\n",
    "test_end_set = datasets.ImageFolder(test_pic, transform=data_args)\n",
    "\n",
    "# 观察路径形式，若不符合，需要修改img_seq加载代码\n",
    "print(test_end_set.imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df8da22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    }
   ],
   "source": [
    "img_seq = []\n",
    "for item in test_end_set.imgs:\n",
    "    name = item[0]\n",
    "    name = name.split('\\\\')[1]\n",
    "    img_seq.append(name)\n",
    "    \n",
    "\n",
    "model.eval()\n",
    "test_end_iter = torch.utils.data.DataLoader(test_end_set, batch_size=batch_size, shuffle=False)\n",
    "tgt = torch.zeros((batch_size, 80),dtype=torch.int64)\n",
    "\n",
    "\n",
    "with open('./img_list.bin', 'wb') as f_img_list:\n",
    "    pickle.dump(img_seq, f_img_list) # 保存图片加载顺序\n",
    "    \n",
    "with open('./test_end_output.txt', 'w', encoding='utf-8') as f_test_out:\n",
    "    with torch.no_grad():\n",
    "        for X, _ in test_end_iter:\n",
    "            tgt = torch.zeros((X.shape[0], 80),dtype=torch.int64)\n",
    "            _, pre_end = model(X, tgt)\n",
    "#             print(pre_end)\n",
    "            for item in pre_end:\n",
    "                decodings = tokenizer.decode(np.argmax(item, axis=-1))\n",
    "                f_test_out.write('Gen:' + ClearSpecialChar(decodings) + '\\n')\n",
    "print('Finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
