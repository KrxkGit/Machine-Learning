{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa22bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,Trainer,TrainingArguments\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.resnet import resnet152, resnet50, resnet18 # 导入 resnet-152\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import pickle\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768a28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder = nn.Linear(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "def Loss(src, tgt):\n",
    "    nTokens = torch.nonzero(tgt==102)[:,1].sum()\n",
    "    # print('loss is called')\n",
    "    # print(src)\n",
    "    # print(tgt)\n",
    "    # src = torch.permute(src, dims=(0, 2, 1)) # 根据官方文档，分类必须在 1 维度\n",
    "    # 展平前两个维度\n",
    "    src = src.contiguous().view(-1, src.shape[-1])\n",
    "    # print(src)\n",
    "    tgt = tgt.contiguous().view(-1)\n",
    "    l = F.cross_entropy(src, tgt) / nTokens * 10\n",
    "    # print('loss', l)\n",
    "    return l\n",
    "\n",
    "class Krxk_model(nn.Module):\n",
    "    def __init__(self, tokenizer, encoder, decoder):\n",
    "        super().__init__()\n",
    "        print('Vocab_size: ', vocab_size)\n",
    "        # self.dev = next(decoder.parameters()).device # 获得 decoder device\n",
    "        self.tokenizer = tokenizer\n",
    "        self.encoder = encoder\n",
    "        self.embed_size = vocab_size\n",
    "        self.transformer_encoder_in_nums = 512\n",
    "        # d_mid = 10\n",
    "        # self.split = nn.Sequential(nn.Linear(self.encoder.fc.out_features, max_length * d_mid), nn.ReLU()) # 用于分割图片特征为序列\n",
    "        # self.fc = nn.Sequential(nn.Linear(d_mid, self.transformer_encoder_in_nums)) # 将 resnet 转化为 全连接\n",
    "        self.embed = nn.Embedding(self.embed_size, self.transformer_encoder_in_nums, padding_idx=self.tokenizer.pad_token_id) # 嵌入为 transformer的in_features维度\n",
    "        # self.bn = nn.BatchNorm1d(self.transformer_encoder_in_nums)\n",
    "        self.decoder = decoder\n",
    "        self.positional_encoding = PositionalEncoding(self.transformer_encoder_in_nums, dropout=0)\n",
    "        self.fc_vocab = nn.Linear(self.transformer_encoder_in_nums, self.embed_size) # transformer 输出映射回词表\n",
    "        \n",
    "        \n",
    "        # 用作临时 caption 测试案例\n",
    "#         test_caption = 'Krxk is a great developer.' \n",
    "#         print(test_caption)\n",
    "#         self.test_caption_tokenized = self.tokenizer.encode(test_caption, return_tensors='pt').repeat(6, 1) # 临时案例中有6张图片\n",
    "#         print(self.test_caption_tokenized.shape)\n",
    "#         print(self.embed(self.test_caption_tokenized).shape)\n",
    "        \n",
    "    def forward(self, X, labels, attention_mask):\n",
    "        encode = self.encoder(X)\n",
    "        # encode_split = self.split(encode)\n",
    "        # encode_split = encode_split.reshape(encode_split.shape[0], max_length, -1)\n",
    "        # print('encode: ',encode.shape)\n",
    "        features = encode.flatten(start_dim=2).permute((0, 2, 1)) # 将图片特征映射为词表特征\n",
    "        # features = self.bn(features)\n",
    "\n",
    "        # print(features) # 测试 Encoder 是否合理\n",
    "        \n",
    "        # 此处将 embeddings 与 resnet 提取的特征进行concat 输入 transformer\n",
    "#         embeddings = torch.concat((embeddings, embeddings), dim=1)\n",
    "        embeddings = self.embed(labels)\n",
    "        # print('embeddings\\n', embeddings)\n",
    "        # f = features.unsqueeze(1)\n",
    "#         print(embeddings.shape, f.shape)\n",
    "        # embeddings_attach = torch.concat((embeddings, features.unsqueeze(1)), dim=1)\n",
    "        # embeddings_attach = features.unsqueeze(1)\n",
    "        embeddings_attach = features\n",
    "        # print(embeddings_attach)\n",
    "        # print('features: ',features.shape)\n",
    "        # print('features\\n', embeddings_attach)\n",
    "\n",
    "        # decode 需要输入 src 与 tgt，分别用作 Transformer 编码器与解码器（输入正确的caption）的输入\n",
    "        dev = next(self.decoder.parameters()).device # 获得 decoder device\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(max_length, device=dev)\n",
    "        \n",
    "        embeddings_attach = self.positional_encoding(embeddings_attach)\n",
    "        embeddings = self.positional_encoding(embeddings)\n",
    "        # print(attention_mask.shape, tgt_mask.shape)\n",
    "\n",
    "        embeddings_attach = torch.permute(embeddings_attach, (1, 0, 2))\n",
    "        embeddings = torch.permute(embeddings, (1, 0, 2))\n",
    "        # attention_mask = None # 暂时去掉\n",
    "        decode = self.decoder(embeddings, embeddings_attach, tgt_key_padding_mask=attention_mask, tgt_mask=tgt_mask)\n",
    "\n",
    "        decode = torch.permute(decode, (1, 0, 2))\n",
    "        decode_ids = self.fc_vocab(decode)\n",
    "        \n",
    "        return Loss(decode_ids, labels),decode # 损失放在第一返回位置\n",
    "    def predictor(self, out):\n",
    "        return self.fc_vocab(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
