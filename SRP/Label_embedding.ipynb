{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad14f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel,AutoConfig,AutoTokenizer,AutoModelForSequenceClassification,Trainer,TrainingArguments,DataCollatorWithPadding\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import evaluate\n",
    "import re\n",
    "# from pygtrans import Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4a8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 加载数据\n",
    "# excel_file = 'd:/基于深度学习的海量文本处理/第1阶段/10w.xlsx'\n",
    "# data_frame = pd.read_excel(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0311064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 随机抽样（预实验使用）\n",
    "# data_frame = data_frame.sample(n=30)\n",
    "# data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3f54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 停用词预处理\n",
    "# stop_words = ['您好','你好',':很高兴为您服务','请问有什么可以帮您','client','user',' ']\n",
    "# sep_words = ['。', '!', '?', ',']\n",
    "# def ProcessStopWords(text):\n",
    "#     for word in stop_words:\n",
    "#         text = text.replace(word,'')\n",
    "#     text = text.replace(':','。').replace('。','',1) # 删除第一个。\n",
    "#     # for word in sep_words:\n",
    "#     #     text = text.replace(word, '[SEP]')\n",
    "#     return text\n",
    "\n",
    "# data_frame['转写文本'] = data_frame['转写文本'].map(ProcessStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a7bd85-a003-4cb6-a9d0-394006be2de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_frame['转写文本'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca7cf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 标签预处理\n",
    "# regex = re.compile(r'^.*?>(.*?)>.*?$')\n",
    "# def ProcessLabels(text):\n",
    "#     text = text.replace('>>','>').replace('10019','')\n",
    "#     text = re.match(regex, text).groups()[0]\n",
    "#     return text\n",
    "\n",
    "# data_frame['服务请求'] = data_frame['服务请求'].map(ProcessLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa56f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预览预处理结果\n",
    "# data_frame['转写文本'].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb821bb-84ce-4d0c-a21e-3177611af8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 训练复盘并分析数据集后，考虑在前面的处理把 样本数<1000 的剔除，即剔除下列：\n",
    "# rm_labels = ['临时','其他','商机','资料信息','业务变更问题','投诉','故障']\n",
    "# for rm_label in rm_labels:\n",
    "#     data_frame.drop(data_frame[data_frame.服务请求 == rm_label].index, inplace=True)\n",
    "# data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dcbb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 翻译转写文本\n",
    "# client = Translate(target='en')\n",
    "# temp = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a3ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 测试\n",
    "# pd.DataFrame(np.array([trans_res.translatedText for trans_res in client.translate(np.array(data_frame['转写文本'].iloc[0:2]).tolist())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a7223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_num = data_frame.shape[0]\n",
    "# batch = 100\n",
    "# epoch = int(total_num/batch)\n",
    "# print(f'共{epoch}部分')\n",
    "# for i in range(epoch):\n",
    "#     if not i == epoch - 1:\n",
    "#         print(f'{i}部分开始')\n",
    "#         translated_res = [trans_res.translatedText for trans_res in client.translate(np.array(data_frame['转写文本'].iloc[i*batch:(i+1)*batch]).tolist())]\n",
    "#     else:\n",
    "#         print('最后一轮开始')\n",
    "#         translated_res = [trans_res.translatedText for trans_res in client.translate(np.array(data_frame['转写文本'].iloc[i*batch:]).tolist())]\n",
    "    \n",
    "#     translated_res = np.array(translated_res)\n",
    "#     temp =  np.concatenate((temp, translated_res), axis=0)\n",
    "#     print(f'第{i}部分已完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32f1ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translated_res = temp\n",
    "# len(translated_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56adb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加入翻译\n",
    "# # data_frame = data_frame.drop(columns=['translated_text'])\n",
    "# data_frame.insert(0, 'translated_text', value=translated_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4118e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 处理翻译出错的符号\n",
    "# def Finetune_translate(text):\n",
    "#     text = text.replace('&#39;','\\'')\n",
    "#     return text\n",
    "    \n",
    "# data_frame['translated_text'] = data_frame['translated_text'].map(Finetune_translate)\n",
    "# data_frame[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf8c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts = np.array(data_frame['translated_text'])\n",
    "# choices = np.array(data_frame['服务请求'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "184539ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_frame['服务请求']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeb83d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 取最大长度\n",
    "# data_frame.insert(data_frame.shape[1], 'text_len',None)\n",
    "# data_frame['text_len'] = data_frame['translated_text'].map(len)\n",
    "# max_length_index = data_frame['text_len'].argmax()\n",
    "# max_length = data_frame['text_len'].iloc[max_length_index]\n",
    "# max_length_index, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18291572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 观察文本长度分布（排除异常值）\n",
    "# data_frame.boxplot('text_len', grid=False, showfliers=False, color='Black')\n",
    "# plt.suptitle(\"\")\n",
    "# plt.xlabel(\"\")\n",
    "# plt.show()\n",
    "# # 由图可知，取512足够覆盖正常样本\n",
    "# max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "790333c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 去重choices，并保存原choices对应去重后的位置\n",
    "# unique_choices = np.unique(choices)\n",
    "# labels = np.array([np.argwhere(unique_choices==v)[0]  for v in choices])\n",
    "# unique_choices.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "929ac497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加入标签\n",
    "# data_frame.insert(0, 'label', value=labels)\n",
    "# data_frame[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f134167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 取出特征与labels\n",
    "# df = data_frame[['label', 'translated_text', '服务请求']]\n",
    "# df[:10]\n",
    "# # 统计\n",
    "# df['label'].value_counts(ascending=True).plot.barh()\n",
    "# plt.title(\"Frequency of Classes\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45f67412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 手动处理样本非均衡情况\n",
    "# df4 = df[df['label'] == 4].sample(n=30000)\n",
    "# df2 = df[df['label'] == 2]\n",
    "# df1 = pd.DataFrame(np.repeat(df[df['label'] == 1].values, 2, axis=0), columns=df.columns)\n",
    "# df0 = pd.DataFrame(np.repeat(df[df['label'] == 0].values, 2, axis=0), columns=df.columns)\n",
    "# df3 = pd.DataFrame(np.repeat(df[df['label'] == 3].values, 2, axis=0), columns=df.columns)\n",
    "\n",
    "# df = pd.concat([df0, df1, df2, df3, df4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5a8d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 先排序 label，以便后续充分打乱\n",
    "# df = df.sort_values(by='服务请求')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b61ae46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_excel_path = './PreProcess.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "930a6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel(save_excel_path) # 保存翻译结果，方便重复使用\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5beb5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于直接读取预处理完成的结果\n",
    "df = pd.read_excel(save_excel_path)\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "df.dropna(inplace=True) # drop 空行，防止 tokenize 失败"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93fb2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 预实验\n",
    "# df = df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5f9d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据经验，人为合并相似分类\n",
    "def CombineLabel(label):\n",
    "    # 仅映射 label 属性\n",
    "    label = 2 if label == 4 else label # 查询与咨询合并\n",
    "    return label\n",
    "\n",
    "df['label'] = df['label'].map(CombineLabel)\n",
    "df = df.sort_values(by='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65cc2c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>服务请求</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey, that is my account. The current network i...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>0</td>\n",
       "      <td>Hello. When can you solve the problem of chang...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638</th>\n",
       "      <td>0</td>\n",
       "      <td>. . Excuse me, a few days ago, I asked you whe...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>0</td>\n",
       "      <td>, I'm glad to serve you. Ah, your phone has be...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>0</td>\n",
       "      <td>I would like to ask my light cat why the red l...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641</th>\n",
       "      <td>0</td>\n",
       "      <td>Hello. gentlemen. Hey, why can’t I access the ...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey, this is my mobile phone number. I see tha...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7643</th>\n",
       "      <td>0</td>\n",
       "      <td>at your service. Well, I would like to ask why...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7644</th>\n",
       "      <td>0</td>\n",
       "      <td>Ah, you just told me that I wanted to check th...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7636</th>\n",
       "      <td>0</td>\n",
       "      <td>Uh, hey, I took a look at my streaming phone b...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                    translated_text 服务请求\n",
       "0         0  Hey, that is my account. The current network i...   不满\n",
       "7637      0  Hello. When can you solve the problem of chang...   不满\n",
       "7638      0  . . Excuse me, a few days ago, I asked you whe...   不满\n",
       "7639      0  , I'm glad to serve you. Ah, your phone has be...   不满\n",
       "7640      0  I would like to ask my light cat why the red l...   不满\n",
       "7641      0  Hello. gentlemen. Hey, why can’t I access the ...   不满\n",
       "7642      0  Hey, this is my mobile phone number. I see tha...   不满\n",
       "7643      0  at your service. Well, I would like to ask why...   不满\n",
       "7644      0  Ah, you just told me that I wanted to check th...   不满\n",
       "7636      0  Uh, hey, I took a look at my streaming phone b...   不满"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预处理结果相关参数\n",
    "max_length = 512\n",
    "classic_num = 4\n",
    "\n",
    "# 预览\n",
    "print(df.shape[0])\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f337b69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['label', 'text', '__index_level_0__'],\n",
       "         num_rows: 79460\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['label', 'text', '__index_level_0__'],\n",
       "         num_rows: 19866\n",
       "     })\n",
       " }),\n",
       " {'label': 0,\n",
       "  'text': \"Hello. Hello, this is your side. Can you help me lift the Internet speed limit? The Internet speed limit cannot be lifted, sir. If it can't be resolved, can I just wait until next month for it to resolve itself? right. If you want to unblock this network setting, you can only use the accelerated traffic package. Then why does he limit the speed even when I use it? For his side, he will have a speed limit rule, but for your side, if the speed is limited, if you want to speed up, you can only buy that kind of data package. ah. Acceleration package. But I have traffic. There is only one kind. Um. Nothing can be solved. That is, only the traffic package acceleration package can be released by purchasing the traffic package acceleration package, and nothing else will work. Okay, okay, no, no, no, thank you, bye. I wish you a happy life bye\",\n",
       "  '__index_level_0__': 7875},\n",
       " {'label': 1,\n",
       "  'text': \"Hello. . I want to cancel the 2 data packages on my number. Let’s check it out for you here. Well, for you, there is a WoShiXiang data package for 20 yuan and a Changxiang rights data package for 19.9 yuan. I canceled both of them. Yes, you can cancel it. You can see it is very discounted. I suggest you keep it. OK, if we want to cancel for you here, we need to verify your identity information. Do you remember the 6-digit service password? If you don't remember, you need to report your name and ID number. Oh, I don't remember. I can just give you my ID number. OK, please tell me your name and ID number. The 1st online question. Yes, please report your ID number. The ID number is. 51062319607178828. Um. Well, please report this ID card address or this contact number. The address is Group 5, Hengliang Village, Honghongdian Town, Zhongjiang County, Sichuan Province. OK So here we have already canceled it for you. Do you think there is anything else that can help you? Ah no more. Okay, thank you for calling and wish you a happy life. Goodbye. OK, bye\",\n",
       "  '__index_level_0__': 15137})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建数据集\n",
    "ds = DatasetDict({'train': Dataset.from_pandas(df)})\n",
    "# ds['train'] = ds['train'].rename_column('转写文本','text')\n",
    "ds = ds.remove_columns(['服务请求'])\n",
    "\n",
    "ds['train'] = ds['train'].rename_columns({'translated_text':'text'})\n",
    "ds = ds['train'].train_test_split(0.2, shuffle=True) # 按 8:2 分割数据集\n",
    "\n",
    "# ds = ds.shuffle(88) # 再次打乱数据集\n",
    "ds, ds['train'][0], ds['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f99bd9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 79460/79460 [00:18<00:00, 4193.92 examples/s]\n",
      "Map: 100%|██████████| 19866/19866 [00:04<00:00, 4172.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 644 ms, total: 1min 31s\n",
      "Wall time: 23.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_path = './gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token='[PAD]'\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=max_length)\n",
    "\n",
    "tokenized_ds = ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6877ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # 允许不同长度tensor的存在\n",
    "model_config = AutoConfig.from_pretrained(model_path)\n",
    "model_config.num_labels = classic_num\n",
    "model_config.pad_token_id = 0\n",
    "model = AutoModelForSequenceClassification.from_config(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "caa78d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': \"Hello. Hello, this is your side. Can you help me lift the Internet speed limit? The Internet speed limit cannot be lifted, sir. If it can't be resolved, can I just wait until next month for it to resolve itself? right. If you want to unblock this network setting, you can only use the accelerated traffic package. Then why does he limit the speed even when I use it? For his side, he will have a speed limit rule, but for your side, if the speed is limited, if you want to speed up, you can only buy that kind of data package. ah. Acceleration package. But I have traffic. There is only one kind. Um. Nothing can be solved. That is, only the traffic package acceleration package can be released by purchasing the traffic package acceleration package, and nothing else will work. Okay, okay, no, no, no, thank you, bye. I wish you a happy life bye\",\n",
       " '__index_level_0__': 7875,\n",
       " 'input_ids': [15496,\n",
       "  13,\n",
       "  18435,\n",
       "  11,\n",
       "  428,\n",
       "  318,\n",
       "  534,\n",
       "  1735,\n",
       "  13,\n",
       "  1680,\n",
       "  345,\n",
       "  1037,\n",
       "  502,\n",
       "  10303,\n",
       "  262,\n",
       "  4455,\n",
       "  2866,\n",
       "  4179,\n",
       "  30,\n",
       "  383,\n",
       "  4455,\n",
       "  2866,\n",
       "  4179,\n",
       "  2314,\n",
       "  307,\n",
       "  13663,\n",
       "  11,\n",
       "  15967,\n",
       "  13,\n",
       "  1002,\n",
       "  340,\n",
       "  460,\n",
       "  470,\n",
       "  307,\n",
       "  12939,\n",
       "  11,\n",
       "  460,\n",
       "  314,\n",
       "  655,\n",
       "  4043,\n",
       "  1566,\n",
       "  1306,\n",
       "  1227,\n",
       "  329,\n",
       "  340,\n",
       "  284,\n",
       "  10568,\n",
       "  2346,\n",
       "  30,\n",
       "  826,\n",
       "  13,\n",
       "  1002,\n",
       "  345,\n",
       "  765,\n",
       "  284,\n",
       "  555,\n",
       "  9967,\n",
       "  428,\n",
       "  3127,\n",
       "  4634,\n",
       "  11,\n",
       "  345,\n",
       "  460,\n",
       "  691,\n",
       "  779,\n",
       "  262,\n",
       "  23312,\n",
       "  4979,\n",
       "  5301,\n",
       "  13,\n",
       "  3244,\n",
       "  1521,\n",
       "  857,\n",
       "  339,\n",
       "  4179,\n",
       "  262,\n",
       "  2866,\n",
       "  772,\n",
       "  618,\n",
       "  314,\n",
       "  779,\n",
       "  340,\n",
       "  30,\n",
       "  1114,\n",
       "  465,\n",
       "  1735,\n",
       "  11,\n",
       "  339,\n",
       "  481,\n",
       "  423,\n",
       "  257,\n",
       "  2866,\n",
       "  4179,\n",
       "  3896,\n",
       "  11,\n",
       "  475,\n",
       "  329,\n",
       "  534,\n",
       "  1735,\n",
       "  11,\n",
       "  611,\n",
       "  262,\n",
       "  2866,\n",
       "  318,\n",
       "  3614,\n",
       "  11,\n",
       "  611,\n",
       "  345,\n",
       "  765,\n",
       "  284,\n",
       "  2866,\n",
       "  510,\n",
       "  11,\n",
       "  345,\n",
       "  460,\n",
       "  691,\n",
       "  2822,\n",
       "  326,\n",
       "  1611,\n",
       "  286,\n",
       "  1366,\n",
       "  5301,\n",
       "  13,\n",
       "  29042,\n",
       "  13,\n",
       "  29805,\n",
       "  341,\n",
       "  5301,\n",
       "  13,\n",
       "  887,\n",
       "  314,\n",
       "  423,\n",
       "  4979,\n",
       "  13,\n",
       "  1318,\n",
       "  318,\n",
       "  691,\n",
       "  530,\n",
       "  1611,\n",
       "  13,\n",
       "  21039,\n",
       "  13,\n",
       "  10528,\n",
       "  460,\n",
       "  307,\n",
       "  16019,\n",
       "  13,\n",
       "  1320,\n",
       "  318,\n",
       "  11,\n",
       "  691,\n",
       "  262,\n",
       "  4979,\n",
       "  5301,\n",
       "  20309,\n",
       "  5301,\n",
       "  460,\n",
       "  307,\n",
       "  2716,\n",
       "  416,\n",
       "  14080,\n",
       "  262,\n",
       "  4979,\n",
       "  5301,\n",
       "  20309,\n",
       "  5301,\n",
       "  11,\n",
       "  290,\n",
       "  2147,\n",
       "  2073,\n",
       "  481,\n",
       "  670,\n",
       "  13,\n",
       "  16805,\n",
       "  11,\n",
       "  8788,\n",
       "  11,\n",
       "  645,\n",
       "  11,\n",
       "  645,\n",
       "  11,\n",
       "  645,\n",
       "  11,\n",
       "  5875,\n",
       "  345,\n",
       "  11,\n",
       "  33847,\n",
       "  13,\n",
       "  314,\n",
       "  4601,\n",
       "  345,\n",
       "  257,\n",
       "  3772,\n",
       "  1204,\n",
       "  33847],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a78c0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估\n",
    "accuracy = evaluate.load('./evaluate/metrics/accuracy/accuracy.py')\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad2d659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam 训练阶段\n",
    "ds = ds.shuffle(88) # 再次打乱数据集\n",
    "training_args = TrainingArguments('/hy-tmp/SRP-checkpoint-output',evaluation_strategy='epoch',save_strategy='epoch', learning_rate=5e-7, \n",
    "                                    load_best_model_at_end=True, num_train_epochs=16)\n",
    "trainer = Trainer(model, args=training_args, train_dataset=tokenized_ds['train'], eval_dataset=tokenized_ds['test'], \n",
    "                  tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78796024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='158928' max='158928' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [158928/158928 4:01:54, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.752800</td>\n",
       "      <td>0.768141</td>\n",
       "      <td>0.733011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.742100</td>\n",
       "      <td>0.775771</td>\n",
       "      <td>0.732961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.732300</td>\n",
       "      <td>0.757588</td>\n",
       "      <td>0.735629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.748800</td>\n",
       "      <td>0.758290</td>\n",
       "      <td>0.734270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.752100</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.736283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.724200</td>\n",
       "      <td>0.755958</td>\n",
       "      <td>0.736132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.769064</td>\n",
       "      <td>0.734823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.715800</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.736434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 1min 49s, sys: 1min 9s, total: 4h 2min 59s\n",
      "Wall time: 4h 1min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=158928, training_loss=0.36715211970777556, metrics={'train_runtime': 14515.0903, 'train_samples_per_second': 87.589, 'train_steps_per_second': 10.949, 'total_flos': 2.138172313524388e+17, 'train_loss': 0.36715211970777556, 'epoch': 16.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 训练\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4522722-55c4-479e-9f47-b8057b4ae453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "res_path = '/hy-tmp/SRP_Business_Classification/'\n",
    "tokenizer.save_pretrained(res_path)\n",
    "model.save_pretrained(res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "946d210a-5dee-4ce8-93c3-5f0b5ef04c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SGD 训练阶段\n",
    "# # ds = ds.shuffle(88) # 再次打乱数据集\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=5e-8)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(epoch+1))\n",
    "# training_args = TrainingArguments('/hy-tmp/SRP-output',evaluation_strategy='epoch',save_strategy='epoch',\n",
    "#                                 load_best_model_at_end=True, num_train_epochs=5)\n",
    "# trainer = Trainer(model, args=training_args, train_dataset=tokenized_ds['train'], eval_dataset=tokenized_ds['test'], \n",
    "#                   tokenizer=tokenizer, data_collator=data_collator, \n",
    "#                   compute_metrics=compute_metrics, optimizers=(optimizer, lr_scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "294f643e-7d67-485f-998f-4c00291efdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 精准训练\n",
    "# trainer.train(resume_from_checkpoint=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
