{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad14f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel,AutoConfig,AutoTokenizer,AutoModelForSequenceClassification,Trainer,TrainingArguments,DataCollatorWithPadding\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import evaluate\n",
    "import re\n",
    "# from pygtrans import Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4a8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 加载数据\n",
    "# excel_file = 'd:/基于深度学习的海量文本处理/第1阶段/10w.xlsx'\n",
    "# data_frame = pd.read_excel(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0311064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 随机抽样（预实验使用）\n",
    "# data_frame = data_frame.sample(n=30)\n",
    "# data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3f54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 停用词预处理\n",
    "# stop_words = ['您好','你好',':很高兴为您服务','请问有什么可以帮您','client','user',' ']\n",
    "# sep_words = ['。', '!', '?', ',']\n",
    "# def ProcessStopWords(text):\n",
    "#     for word in stop_words:\n",
    "#         text = text.replace(word,'')\n",
    "#     text = text.replace(':','。').replace('。','',1) # 删除第一个。\n",
    "#     # for word in sep_words:\n",
    "#     #     text = text.replace(word, '[SEP]')\n",
    "#     return text\n",
    "\n",
    "# data_frame['转写文本'] = data_frame['转写文本'].map(ProcessStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a7bd85-a003-4cb6-a9d0-394006be2de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_frame['转写文本'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca7cf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 标签预处理\n",
    "# regex = re.compile(r'^.*?>(.*?)>.*?$')\n",
    "# def ProcessLabels(text):\n",
    "#     text = text.replace('>>','>').replace('10019','')\n",
    "#     text = re.match(regex, text).groups()[0]\n",
    "#     return text\n",
    "\n",
    "# data_frame['服务请求'] = data_frame['服务请求'].map(ProcessLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa56f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预览预处理结果\n",
    "# data_frame['转写文本'].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb821bb-84ce-4d0c-a21e-3177611af8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 训练复盘并分析数据集后，考虑在前面的处理把 样本数<1000 的剔除，即剔除下列：\n",
    "# rm_labels = ['临时','其他','商机','资料信息','业务变更问题','投诉','故障']\n",
    "# for rm_label in rm_labels:\n",
    "#     data_frame.drop(data_frame[data_frame.服务请求 == rm_label].index, inplace=True)\n",
    "# data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dcbb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 翻译转写文本\n",
    "# client = Translate(target='en')\n",
    "# temp = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a3ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 测试\n",
    "# pd.DataFrame(np.array([trans_res.translatedText for trans_res in client.translate(np.array(data_frame['转写文本'].iloc[0:2]).tolist())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a7223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_num = data_frame.shape[0]\n",
    "# batch = 100\n",
    "# epoch = int(total_num/batch)\n",
    "# print(f'共{epoch}部分')\n",
    "# for i in range(epoch):\n",
    "#     if not i == epoch - 1:\n",
    "#         print(f'{i}部分开始')\n",
    "#         translated_res = [trans_res.translatedText for trans_res in client.translate(np.array(data_frame['转写文本'].iloc[i*batch:(i+1)*batch]).tolist())]\n",
    "#     else:\n",
    "#         print('最后一轮开始')\n",
    "#         translated_res = [trans_res.translatedText for trans_res in client.translate(np.array(data_frame['转写文本'].iloc[i*batch:]).tolist())]\n",
    "    \n",
    "#     translated_res = np.array(translated_res)\n",
    "#     temp =  np.concatenate((temp, translated_res), axis=0)\n",
    "#     print(f'第{i}部分已完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32f1ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translated_res = temp\n",
    "# len(translated_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56adb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加入翻译\n",
    "# # data_frame = data_frame.drop(columns=['translated_text'])\n",
    "# data_frame.insert(0, 'translated_text', value=translated_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4118e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 处理翻译出错的符号\n",
    "# def Finetune_translate(text):\n",
    "#     text = text.replace('&#39;','\\'')\n",
    "#     return text\n",
    "    \n",
    "# data_frame['translated_text'] = data_frame['translated_text'].map(Finetune_translate)\n",
    "# data_frame[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf8c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts = np.array(data_frame['translated_text'])\n",
    "# choices = np.array(data_frame['服务请求'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "184539ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_frame['服务请求']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeb83d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 取最大长度\n",
    "# data_frame.insert(data_frame.shape[1], 'text_len',None)\n",
    "# data_frame['text_len'] = data_frame['translated_text'].map(len)\n",
    "# max_length_index = data_frame['text_len'].argmax()\n",
    "# max_length = data_frame['text_len'].iloc[max_length_index]\n",
    "# max_length_index, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18291572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 观察文本长度分布（排除异常值）\n",
    "# data_frame.boxplot('text_len', grid=False, showfliers=False, color='Black')\n",
    "# plt.suptitle(\"\")\n",
    "# plt.xlabel(\"\")\n",
    "# plt.show()\n",
    "# # 由图可知，取512足够覆盖正常样本\n",
    "# max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "790333c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 去重choices，并保存原choices对应去重后的位置\n",
    "# unique_choices = np.unique(choices)\n",
    "# labels = np.array([np.argwhere(unique_choices==v)[0]  for v in choices])\n",
    "# unique_choices.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "929ac497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加入标签\n",
    "# data_frame.insert(0, 'label', value=labels)\n",
    "# data_frame[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f134167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 取出特征与labels\n",
    "# df = data_frame[['label', 'translated_text', '服务请求']]\n",
    "# df[:10]\n",
    "# # 统计\n",
    "# df['label'].value_counts(ascending=True).plot.barh()\n",
    "# plt.title(\"Frequency of Classes\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45f67412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 手动处理样本非均衡情况\n",
    "# df4 = df[df['label'] == 4].sample(n=30000)\n",
    "# df2 = df[df['label'] == 2]\n",
    "# df1 = pd.DataFrame(np.repeat(df[df['label'] == 1].values, 2, axis=0), columns=df.columns)\n",
    "# df0 = pd.DataFrame(np.repeat(df[df['label'] == 0].values, 2, axis=0), columns=df.columns)\n",
    "# df3 = pd.DataFrame(np.repeat(df[df['label'] == 3].values, 2, axis=0), columns=df.columns)\n",
    "\n",
    "# df = pd.concat([df0, df1, df2, df3, df4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5a8d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 先排序 label，以便后续充分打乱\n",
    "# df = df.sort_values(by='服务请求')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b61ae46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_excel_path = './PreProcess.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "930a6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel(save_excel_path) # 保存翻译结果，方便重复使用\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5beb5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于直接读取预处理完成的结果\n",
    "df = pd.read_excel(save_excel_path)\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "df.dropna(inplace=True) # drop 空行，防止 tokenize 失败"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5f9d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据经验，人为合并相似分类\n",
    "def CombineLabel(label):\n",
    "    # 仅映射 label 属性\n",
    "    label = 2 if label == 4 else label # 查询与咨询合并\n",
    "    return label\n",
    "\n",
    "df['label'] = df['label'].map(CombineLabel)\n",
    "df = df.sort_values(by='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65cc2c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>服务请求</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey, that is my account. The current network i...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>0</td>\n",
       "      <td>Hello. When can you solve the problem of chang...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638</th>\n",
       "      <td>0</td>\n",
       "      <td>. . Excuse me, a few days ago, I asked you whe...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>0</td>\n",
       "      <td>, I'm glad to serve you. Ah, your phone has be...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>0</td>\n",
       "      <td>I would like to ask my light cat why the red l...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641</th>\n",
       "      <td>0</td>\n",
       "      <td>Hello. gentlemen. Hey, why can’t I access the ...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey, this is my mobile phone number. I see tha...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7643</th>\n",
       "      <td>0</td>\n",
       "      <td>at your service. Well, I would like to ask why...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7644</th>\n",
       "      <td>0</td>\n",
       "      <td>Ah, you just told me that I wanted to check th...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7636</th>\n",
       "      <td>0</td>\n",
       "      <td>Uh, hey, I took a look at my streaming phone b...</td>\n",
       "      <td>不满</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                    translated_text 服务请求\n",
       "0         0  Hey, that is my account. The current network i...   不满\n",
       "7637      0  Hello. When can you solve the problem of chang...   不满\n",
       "7638      0  . . Excuse me, a few days ago, I asked you whe...   不满\n",
       "7639      0  , I'm glad to serve you. Ah, your phone has be...   不满\n",
       "7640      0  I would like to ask my light cat why the red l...   不满\n",
       "7641      0  Hello. gentlemen. Hey, why can’t I access the ...   不满\n",
       "7642      0  Hey, this is my mobile phone number. I see tha...   不满\n",
       "7643      0  at your service. Well, I would like to ask why...   不满\n",
       "7644      0  Ah, you just told me that I wanted to check th...   不满\n",
       "7636      0  Uh, hey, I took a look at my streaming phone b...   不满"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预处理结果相关参数\n",
    "max_length = 512\n",
    "classic_num = 4\n",
    "\n",
    "# 预览\n",
    "print(df.shape[0])\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f337b69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['label', 'text', '__index_level_0__'],\n",
       "         num_rows: 79460\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['label', 'text', '__index_level_0__'],\n",
       "         num_rows: 19866\n",
       "     })\n",
       " }),\n",
       " {'label': 2,\n",
       "  'text': \"Hey, I want to ask if you have anyone who can use it when making phone calls. If you open a high-definition or something. Well, the one with high-definition voice function, right? If you enable it, you don’t need to do it, right? Well, that one is free of charge. Then help me open it. OK please wait. Your number has already been enabled for this feature. Yes, this function has been enabled. Oh oh oh that's it. Okay, thank you for calling and wish you a happy life. Goodbye. Um\",\n",
       "  '__index_level_0__': 43949},\n",
       " {'label': 2,\n",
       "  'text': \". . I told you last month that this is next to Phoenix Avenue in Longgang. Your signal is too poor. You said that the fault problem is being repaired. Have you not repaired it yet? Wait a moment and let me take a look at it for you. Is your signal bad? yes. If I checked it for you, it has been restored now. Then why is the signal signal so bad? Well, let me help you in the backend to make a backend system to repair this network data. Can you think of it? Hey, it’s okay, it’s okay. Well, during the repair period, if it takes about 5 minutes, you can restart it. Well, okay, okay, okay. Then I won't bother you here. I wish you a happy life. Goodbye. Yeah. thanks, thanks\",\n",
       "  '__index_level_0__': 89033})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建数据集\n",
    "ds = DatasetDict({'train': Dataset.from_pandas(df)})\n",
    "# ds['train'] = ds['train'].rename_column('转写文本','text')\n",
    "ds = ds.remove_columns(['服务请求'])\n",
    "\n",
    "ds['train'] = ds['train'].rename_columns({'translated_text':'text'})\n",
    "ds = ds['train'].train_test_split(0.2, shuffle=True) # 按 8:2 分割数据集\n",
    "\n",
    "# ds = ds.shuffle(88) # 再次打乱数据集\n",
    "ds, ds['train'][0], ds['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f99bd9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 79460/79460 [00:25<00:00, 3128.45 examples/s]\n",
      "Map: 100%|██████████| 19866/19866 [00:05<00:00, 3364.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 38s, sys: 729 ms, total: 1min 39s\n",
      "Wall time: 31.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_path = './bert-base-cased/'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=max_length)\n",
    "\n",
    "tokenized_ds = ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6877ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # 允许不同长度tensor的存在\n",
    "model_config = AutoConfig.from_pretrained(model_path)\n",
    "model_config.num_labels = classic_num\n",
    "model = AutoModelForSequenceClassification.from_config(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "caa78d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 2,\n",
       " 'text': \"Hey, I want to ask if you have anyone who can use it when making phone calls. If you open a high-definition or something. Well, the one with high-definition voice function, right? If you enable it, you don’t need to do it, right? Well, that one is free of charge. Then help me open it. OK please wait. Your number has already been enabled for this feature. Yes, this function has been enabled. Oh oh oh that's it. Okay, thank you for calling and wish you a happy life. Goodbye. Um\",\n",
       " '__index_level_0__': 43949,\n",
       " 'input_ids': [101,\n",
       "  4403,\n",
       "  117,\n",
       "  146,\n",
       "  1328,\n",
       "  1106,\n",
       "  2367,\n",
       "  1191,\n",
       "  1128,\n",
       "  1138,\n",
       "  2256,\n",
       "  1150,\n",
       "  1169,\n",
       "  1329,\n",
       "  1122,\n",
       "  1165,\n",
       "  1543,\n",
       "  2179,\n",
       "  3675,\n",
       "  119,\n",
       "  1409,\n",
       "  1128,\n",
       "  1501,\n",
       "  170,\n",
       "  1344,\n",
       "  118,\n",
       "  5754,\n",
       "  1137,\n",
       "  1380,\n",
       "  119,\n",
       "  2119,\n",
       "  117,\n",
       "  1103,\n",
       "  1141,\n",
       "  1114,\n",
       "  1344,\n",
       "  118,\n",
       "  5754,\n",
       "  1490,\n",
       "  3053,\n",
       "  117,\n",
       "  1268,\n",
       "  136,\n",
       "  1409,\n",
       "  1128,\n",
       "  9396,\n",
       "  1122,\n",
       "  117,\n",
       "  1128,\n",
       "  1274,\n",
       "  787,\n",
       "  189,\n",
       "  1444,\n",
       "  1106,\n",
       "  1202,\n",
       "  1122,\n",
       "  117,\n",
       "  1268,\n",
       "  136,\n",
       "  2119,\n",
       "  117,\n",
       "  1115,\n",
       "  1141,\n",
       "  1110,\n",
       "  1714,\n",
       "  1104,\n",
       "  2965,\n",
       "  119,\n",
       "  1599,\n",
       "  1494,\n",
       "  1143,\n",
       "  1501,\n",
       "  1122,\n",
       "  119,\n",
       "  10899,\n",
       "  4268,\n",
       "  3074,\n",
       "  119,\n",
       "  2353,\n",
       "  1295,\n",
       "  1144,\n",
       "  1640,\n",
       "  1151,\n",
       "  8824,\n",
       "  1111,\n",
       "  1142,\n",
       "  2672,\n",
       "  119,\n",
       "  2160,\n",
       "  117,\n",
       "  1142,\n",
       "  3053,\n",
       "  1144,\n",
       "  1151,\n",
       "  8824,\n",
       "  119,\n",
       "  2048,\n",
       "  9294,\n",
       "  9294,\n",
       "  1115,\n",
       "  112,\n",
       "  188,\n",
       "  1122,\n",
       "  119,\n",
       "  3956,\n",
       "  117,\n",
       "  6243,\n",
       "  1128,\n",
       "  1111,\n",
       "  3516,\n",
       "  1105,\n",
       "  3683,\n",
       "  1128,\n",
       "  170,\n",
       "  2816,\n",
       "  1297,\n",
       "  119,\n",
       "  15938,\n",
       "  119,\n",
       "  12189,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a78c0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估\n",
    "accuracy = evaluate.load('./evaluate/metrics/accuracy/accuracy.py')\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad2d659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam 训练阶段\n",
    "ds = ds.shuffle(88) # 再次打乱数据集\n",
    "training_args = TrainingArguments('/hy-tmp/SRP-output_2',evaluation_strategy='epoch',save_strategy='epoch', learning_rate=5e-7, \n",
    "                                    load_best_model_at_end=True, num_train_epochs=8)\n",
    "trainer = Trainer(model, args=training_args, train_dataset=tokenized_ds['train'], eval_dataset=tokenized_ds['test'], \n",
    "                  tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78796024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='79464' max='79464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [79464/79464 4:00:18, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.893700</td>\n",
       "      <td>0.868890</td>\n",
       "      <td>0.708245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.835700</td>\n",
       "      <td>0.855034</td>\n",
       "      <td>0.710611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.831036</td>\n",
       "      <td>0.718514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.813295</td>\n",
       "      <td>0.721786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.794400</td>\n",
       "      <td>0.801358</td>\n",
       "      <td>0.717407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.797423</td>\n",
       "      <td>0.721585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.778400</td>\n",
       "      <td>0.790924</td>\n",
       "      <td>0.723346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.791109</td>\n",
       "      <td>0.723246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 16s, sys: 57.3 s, total: 4h 1min 14s\n",
      "Wall time: 4h 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=79464, training_loss=0.8143897118506493, metrics={'train_runtime': 14420.3835, 'train_samples_per_second': 44.082, 'train_steps_per_second': 5.511, 'total_flos': 1.1144159508469978e+17, 'train_loss': 0.8143897118506493, 'epoch': 8.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 训练\n",
    "trainer.train(resume_from_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4522722-55c4-479e-9f47-b8057b4ae453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "res_path = './SRP_Business_Classification/'\n",
    "tokenizer.save_pretrained(res_path)\n",
    "model.save_pretrained(res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "946d210a-5dee-4ce8-93c3-5f0b5ef04c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SGD 训练阶段\n",
    "# # ds = ds.shuffle(88) # 再次打乱数据集\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=5e-8)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(epoch+1))\n",
    "# training_args = TrainingArguments('/hy-tmp/SRP-output',evaluation_strategy='epoch',save_strategy='epoch',\n",
    "#                                 load_best_model_at_end=True, num_train_epochs=5)\n",
    "# trainer = Trainer(model, args=training_args, train_dataset=tokenized_ds['train'], eval_dataset=tokenized_ds['test'], \n",
    "#                   tokenizer=tokenizer, data_collator=data_collator, \n",
    "#                   compute_metrics=compute_metrics, optimizers=(optimizer, lr_scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "294f643e-7d67-485f-998f-4c00291efdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 精准训练\n",
    "# trainer.train(resume_from_checkpoint=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
